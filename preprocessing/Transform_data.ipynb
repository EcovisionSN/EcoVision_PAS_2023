{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPaNI2nPQbmrAPFeRMGOD1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EcovisionSN/EcoVision_PAS_2023/blob/dev/preprocessing/Transform_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HqlkrJnqwKYC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from random import shuffle\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import skimage.io as io\n",
        "import numpy as np\n",
        "import random\n",
        "import PIL\n",
        "import sys\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Montage de drive"
      ],
      "metadata": {
        "id": "LpxTyaPLwWti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E5QPcyjwT1O",
        "outputId": "26a7a058-9814-423d-f7b1-43fdd456fb3d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_name = \"/content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/dataset_16_10_2023\"\n",
        "if not os.path.exists(dir_name):\n",
        "  print(f\"[INFO] Directory with dataset: {dir_name} not found. Unpacking backup...\")\n",
        "  !unzip /content/drive/MyDrive/Notebooks/Dataset/dataset_16_10_2023.zip -d {dir_name}\n",
        "else:\n",
        "  print(f\"[INFO] Directory with dataset: {dir_name} was found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "galeRlbswbmq",
        "outputId": "7bbd67a7-66b2-4ea3-b47d-1ece3a12650a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Directory with dataset: /content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/dataset_16_10_2023 was found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Définition des fonctions d'aide"
      ],
      "metadata": {
        "id": "Bo85PUzQxPQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "def preprocess_one_hot_encode(image_rgb):\n",
        "    img = np.copy(image_rgb[..., 0])\n",
        "    for i, num in enumerate([11, 226, 51]):\n",
        "        img[img == num] = i\n",
        "    one_hot = tf.keras.utils.to_categorical(img, 3)\n",
        "    return one_hot\n",
        "\n",
        "def list_dataset(path):\n",
        "  \"\"\"\n",
        "  path - (/content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/data/)[train/dev]/[image/mask]/img\n",
        "  \"\"\"\n",
        "  prefix_train_mask = \"/train/mask175/img\"\n",
        "  prefix_train_image = \"/train/image/img\"\n",
        "  prefix_dev_mask = \"/dev/mask/img\"\n",
        "  prefix_dev_image = \"/dev/image/img\"\n",
        "\n",
        "  images_train = [f\"{f}\" for f in listdir(path + prefix_train_image) if f.endswith(\".png\")]\n",
        "  images_dev = [f\"{f}\" for f in listdir(path + prefix_dev_image) if f.endswith(\".png\")]\n",
        "  print(f\"[INFO] Found train images: {len(listdir(path + prefix_train_image))}\")\n",
        "  print(f\"[INFO] Found train masks: {len(listdir(path + prefix_train_mask))}\")\n",
        "\n",
        "  pairs_train = [(f\"{path}{prefix_train_image}/{f}\", f\"{path}{prefix_train_mask}/{f}\") for f in images_train]\n",
        "  pairs_dev = [(f\"{path}{prefix_dev_image}/{f}\", f\"{path}{prefix_dev_mask}/{f}\") for f in images_dev]\n",
        "\n",
        "  return [pairs_train, pairs_dev]\n",
        "\n",
        "def list_dataset_new(path):\n",
        "  \"\"\"\n",
        "  path - (/content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/data/)[images/masks]\n",
        "  \"\"\"\n",
        "  prefix_mask = \"/masks\"\n",
        "  prefix_image = \"/images\"\n",
        "\n",
        "  images = [f\"{f}\" for f in listdir(path + prefix_image) if f.endswith(\".png\")]\n",
        "  masks = images.copy()\n",
        "  print(f\"[INFO] Found train images: {len(listdir(path + prefix_image))}\")\n",
        "  print(f\"[INFO] Found train masks: {len(listdir(path + prefix_mask))}\")\n",
        "\n",
        "  pairs_train = [(f\"{path}{prefix_image}/{f}\", f\"{path}{prefix_mask}/{f}\") for f in images]\n",
        "\n",
        "  return pairs_train\n",
        "\n",
        "l = list_dataset_new(\"/content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/dataset_16_10_2023/data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwcxPnEZxCbm",
        "outputId": "d0ddd508-97c6-426d-d1fe-c07ec27b0098"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Found train images: 1500\n",
            "[INFO] Found train masks: 1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def printDivisors(n) :\n",
        "    i = 1\n",
        "    ls = []\n",
        "    while i <= n :\n",
        "        if (n % i==0) :\n",
        "            ls.append(i),\n",
        "        i = i + 1\n",
        "    return ls\n",
        "\n",
        "# Helper functions for defining tf types\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def write_image_annotation_pairs_to_tfrecord(filename_pairs, tfrecords_filename):\n",
        "    writer = tf.io.TFRecordWriter(tfrecords_filename)\n",
        "\n",
        "    for img_path, mask_path in filename_pairs:\n",
        "\n",
        "        img = open(img_path, 'rb').read()\n",
        "        annotation = open(mask_path, 'rb').read()\n",
        "        mask = np.asarray(Image.open(mask_path))\n",
        "        mask_one_channel = np.copy(mask[..., 0])\n",
        "        for i, num in enumerate([11, 226, 51]):\n",
        "            mask_one_channel[mask_one_channel == num] = i\n",
        "\n",
        "        mask_one_channel = np.clip(mask_one_channel, 0, 2)  # Nouvelle ligne ajoutée\n",
        "\n",
        "        mask_one_hot = tf.keras.utils.to_categorical(mask_one_channel, 3).ravel().tobytes()\n",
        "\n",
        "        example = tf.train.Example(features=tf.train.Features(feature={\n",
        "              'image': _bytes_feature(img),\n",
        "              'mask': _bytes_feature(mask_one_hot),\n",
        "              }))\n",
        "\n",
        "        writer.write(example.SerializeToString())\n",
        "    writer.close()"
      ],
      "metadata": {
        "id": "ht4dHxg2xtX8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Créer des tfrecord à partir de fichiers et les enregistrer"
      ],
      "metadata": {
        "id": "FFfxAMd71Xn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset_dir = \"data_balanced\"\n",
        "# filename_pairs = list_dataset(f\"/content/gdrive/MyDrive/Dataset/dataset_raw/{dataset_dir}\")\n",
        "filename_pairs = list_dataset_new(\"/content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/dataset_16_10_2023/data\")\n",
        "# 0 - element is train dataset, 1 - element is dev dataset\n",
        "shuffle(filename_pairs)\n",
        "possible_amounts = printDivisors(len(filename_pairs))\n",
        "print(f'[INFO] Good dataset sizes: ')\n",
        "for i in possible_amounts:\n",
        "  print(f\"- {i}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-jhLAEn1UwT",
        "outputId": "c1342f91-4eca-48fa-996e-7e22256ebab8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Found train images: 1500\n",
            "[INFO] Found train masks: 1500\n",
            "[INFO] Good dataset sizes: \n",
            "- 1\n",
            "- 2\n",
            "- 3\n",
            "- 4\n",
            "- 5\n",
            "- 6\n",
            "- 10\n",
            "- 12\n",
            "- 15\n",
            "- 20\n",
            "- 25\n",
            "- 30\n",
            "- 50\n",
            "- 60\n",
            "- 75\n",
            "- 100\n",
            "- 125\n",
            "- 150\n",
            "- 250\n",
            "- 300\n",
            "- 375\n",
            "- 500\n",
            "- 750\n",
            "- 1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfrecords_filename_template = \"/content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/bucket/tfrecords_v2_part_{}.tfrec\"\n",
        "\n",
        "for i in range(1501):\n",
        "  filename = tfrecords_filename_template.format(i)\n",
        "  if os.path.exists(filename):\n",
        "    os.remove(filename)\n",
        "    print(f\"Removed {filename}\")\n",
        "# if  os.path.exists(tfrecords_filename_dev):\n",
        "#     os.remove(tfrecords_filename_dev)\n",
        "#     print(\"Removed dev.tfrec\")\n",
        "\n",
        "print(\"[INFO] Writing started!\")\n",
        "\n",
        "photos_in_tfrecord = 100\n",
        "counter = 0\n",
        "\n",
        "for i in range(len(filename_pairs)):\n",
        "  filename = tfrecords_filename_template.format(i+1)\n",
        "  files = filename_pairs[i * photos_in_tfrecord : i * photos_in_tfrecord + photos_in_tfrecord]\n",
        "\n",
        "  if i * photos_in_tfrecord > len(filename_pairs):\n",
        "    break\n",
        "  if len(filename_pairs[(i+1) * photos_in_tfrecord : (i+1) * photos_in_tfrecord + photos_in_tfrecord]) < photos_in_tfrecord:\n",
        "    files = filename_pairs[i * photos_in_tfrecord : (i+1) * photos_in_tfrecord + photos_in_tfrecord]\n",
        "    write_image_annotation_pairs_to_tfrecord(files, filename)\n",
        "    print(f'[INFO] File : {filename} written, with {photos_in_tfrecord} pairs of the photos.')\n",
        "    counter += 1\n",
        "    break\n",
        "\n",
        "  write_image_annotation_pairs_to_tfrecord(files, filename)\n",
        "  print(f'[INFO] File : {filename} written, with {photos_in_tfrecord} pairs of the photos.')\n",
        "  counter += 1\n",
        "\n",
        "print(f\"[INFO] Files created : {counter}.\")\n",
        "# write_image_annotation_pairs_to_tfrecord(filename_pairs, tfrecords_filename_template)\n",
        "# print(\"Dev dataset written.\")\n",
        "# write_image_annotation_pairs_to_tfrecord(filename_pairs[0], tfrecords_filename_train)\n",
        "# print(\"Train dataset written.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpOZOS-o1oIx",
        "outputId": "28f50bdf-fba3-4b10-b4ee-cbb6d9eee057"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Writing started!\n",
            "[INFO] File : /content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/bucket/tfrecords_v2_part_1.tfrec written, with 100 pairs of the photos.\n",
            "[INFO] File : /content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/bucket/tfrecords_v2_part_2.tfrec written, with 100 pairs of the photos.\n",
            "[INFO] File : /content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/bucket/tfrecords_v2_part_3.tfrec written, with 100 pairs of the photos.\n",
            "[INFO] File : /content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/bucket/tfrecords_v2_part_4.tfrec written, with 100 pairs of the photos.\n",
            "[INFO] File : /content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/bucket/tfrecords_v2_part_5.tfrec written, with 100 pairs of the photos.\n",
            "[INFO] File : /content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/bucket/tfrecords_v2_part_6.tfrec written, with 100 pairs of the photos.\n",
            "[INFO] File : /content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/bucket/tfrecords_v2_part_7.tfrec written, with 100 pairs of the photos.\n",
            "[INFO] File : /content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/bucket/tfrecords_v2_part_8.tfrec written, with 100 pairs of the photos.\n",
            "[INFO] File : /content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/bucket/tfrecords_v2_part_9.tfrec written, with 100 pairs of the photos.\n",
            "[INFO] File : /content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/bucket/tfrecords_v2_part_10.tfrec written, with 100 pairs of the photos.\n",
            "[INFO] File : /content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/bucket/tfrecords_v2_part_11.tfrec written, with 100 pairs of the photos.\n",
            "[INFO] File : /content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/bucket/tfrecords_v2_part_12.tfrec written, with 100 pairs of the photos.\n",
            "[INFO] File : /content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/bucket/tfrecords_v2_part_13.tfrec written, with 100 pairs of the photos.\n",
            "[INFO] File : /content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/bucket/tfrecords_v2_part_14.tfrec written, with 100 pairs of the photos.\n",
            "[INFO] File : /content/drive/MyDrive/ECOVISION_PAS_CHALLENGE/Dataset/bucket/tfrecords_v2_part_15.tfrec written, with 100 pairs of the photos.\n",
            "[INFO] Files created : 15.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AX3CQAnB2lDp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}